---
title: 模拟面试问答之经典网络模型四：YOLOv1
date: 2020-07-17 19:58:54
tags: 	
	- 深度学习
	- 目标检测
	- 经典网络
categories:
	- 面试
mathjax: true
---

本文总结了面试过程中可能问到的关于YOLOv1模型的一些问题。

[论文地址：You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)

![](1.png)

<center><b>图1 YOLOv1网络结构图</b></center>

<!--more-->

# 简述一下YOLOv1测试时的检测流程？

1. 调整输入图像尺寸为448×448×3。
2. 经过24层卷积输出7×7×1024特征图（64×下采样），再通过一个全连接层输出4096维特征，最后经过一个全连接层输出S×S×30的特征图。（Fast YOLO包括9个卷积）
3. 通过NMS筛选最终结果，NMS的`score=某个类别的概率×置信度`。

# YOLOv1的创新点有哪些？

1. 将检测问题转化为回归问题，同时输出预测框的坐标信息和类别概率。
2. 没有提取候选区域的过程。

# 网络最后输出7×7×30特征图的含义？

YOLOv1将图片划分为7×7个格子，每个格子负责预测中心点落在该格子区域的物体，每个格子预测两个矩形框。每个格子最后输出30个预测值，包括两个矩形框的位置信息`(x, y, w, h)`和置信度，以及20个类别的概率。

# YOLOv1是如何训练的？

1. 在ImageNet上对前20个卷积层进行预训练，具体地，训练时输入尺寸为224×224，网络结构为前20个卷积层+平均池化层+1000全连接层。

2. 添加4个卷积层和两个全连接层，第一个全连接层后添加一个0.5的dropout层。输入尺寸为448×448，激活函数采用Leaky-ReLU（最后一层使用线性激活函数），优化方法采用0.9的Momentum，数据增强采用随机缩放，随机截取，随机调整曝光度和饱和度。

3. Loss函数由五个平方和误差（L2损失）组成：

   ![](2.png)

   其中$\lambda_{coord}=5$，$\lambda_{noobj}=0.5$，由于含有物体的格子较少，因此加大含有物体的格子的损失贡献。

   - 第一行为与ground-truth的IoU较大的预测框的中心点坐标损失；
   - 第二行为与ground-truth的IoU较大的预测框的宽高损失，取根号是为了消除大尺寸框与小尺寸框之间的差异；
   - 第三行和第四行是两个预测框的置信度损失，若格子不含物体则置信度为0，否则为IoU；
   - 第五行为格子的类别损失。

   对于有物体的格子，需要计算分类损失，两个框的置信度损失，IoU较大的框的位置损失。

   对于没物体的格子，只需要计算两个框的置信度损失。

# YOLOv1回归的坐标值是什么含义？

$(x,y)$是格子左上角坐标的偏移值（0-1），$(w,h)$预测的是预测框的宽高与原始图像宽高的比值（0-1）。

# 总结

YOLOv1具有运行速度快，背景误检率等优点，但由于其设置，每个格子最多只能检测一个物体，导致易漏检中心距离近的物体，召回率低，位置准确性较差。