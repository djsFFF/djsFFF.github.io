<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>模拟面试问答之经典网络模型一：RCNN</title>
    <url>/2020/06/13/RCNN/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于RCNN模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">论文地址：Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation</a><br><img src="/2020/06/13/RCNN/1.png" alt="RCNN网络结构"></p>
<center><b>图1 RCNN网络结构图</b></center>

<a id="more"></a>

<h1 id="简述一下RCNN测试时的检测流程？"><a href="#简述一下RCNN测试时的检测流程？" class="headerlink" title="简述一下RCNN测试时的检测流程？"></a>简述一下RCNN测试时的检测流程？</h1><ol>
<li>使用Selective Search在输入图像上提取约2000个候选区域。</li>
<li>缩放每个候选区域到固定尺寸大小，227×227。</li>
<li>将每个候选区域分别输入CNN网络提取特征。</li>
<li>使用二分类SVM分别对每个候选区域进行分类。</li>
<li>对每个类别进行NMS（非极大抑制）。</li>
<li>使用线性回归器分别修正每个候选区域的位置。</li>
</ol>
<h1 id="RCNN是如何对候选区域进行缩放的？"><a href="#RCNN是如何对候选区域进行缩放的？" class="headerlink" title="RCNN是如何对候选区域进行缩放的？"></a>RCNN是如何对候选区域进行缩放的？</h1><p>各向异性缩放且padding=16。</p>
<h1 id="分别介绍一下各向异性和各项同性的缩放？"><a href="#分别介绍一下各向异性和各项同性的缩放？" class="headerlink" title="分别介绍一下各向异性和各项同性的缩放？"></a>分别介绍一下各向异性和各项同性的缩放？</h1><ol>
<li>各向异性直接把图像的宽高拉伸到目标尺寸。</li>
<li>各项同性先按原图像比例进行缩放，然后在再填充到目标尺寸。</li>
</ol>
<h1 id="RCNN的CNN网络是如何训练的？"><a href="#RCNN的CNN网络是如何训练的？" class="headerlink" title="RCNN的CNN网络是如何训练的？"></a>RCNN的CNN网络是如何训练的？</h1><p><img src="/2020/06/13/RCNN/2.jpg" alt="AlexNet网络结构"></p>
<center><b>图2 AlexNet网络结构图</b></center>

<ol>
<li>使用AlexNet(网络结构如<strong>图2</strong>所示)或其他主干网络（如VGG16），先在ILSVRC2012的图像分类数据集上进行预训练，最后一层输出维度为1000。</li>
<li>将AlexNet最后的1000维Softmax层替换为随机初始化的20+1维Softmax层，其余层使用预训练得到的参数进行初始化，在PASCAL VOC数据集上对预训练后的AlexNet进行fine-tuning（微调）。</li>
<li>Fine-tuning时，定义与ground-truth的IoU大于0.5的候选区域为正样本，否则为负样本（即背景样本），在每次迭代时，采样32个正样本和96个负样本组成一个128的mini-batch。</li>
</ol>
<h1 id="RCNN的SVM分类器是如何训练的？"><a href="#RCNN的SVM分类器是如何训练的？" class="headerlink" title="RCNN的SVM分类器是如何训练的？"></a>RCNN的SVM分类器是如何训练的？</h1><ol>
<li>共训练20个二分类SVM。</li>
<li>使用fine-tuning训练后且去掉最后softmax层的AlexNet提取候选区域的特征作为SVM的输入。</li>
<li>定义IoU小于0.3的候选区域为负样本，并进行难负样本挖掘，完整包含物体（IoU=1）的候选区域为正样本，其余样本舍弃。</li>
</ol>
<h1 id="RCNN的线性回归器是如何训练的？"><a href="#RCNN的线性回归器是如何训练的？" class="headerlink" title="RCNN的线性回归器是如何训练的？"></a>RCNN的线性回归器是如何训练的？</h1><ol>
<li>共训练20×4个回归器，正则项系数$\lambda$=10000。</li>
<li>输入为AlexNet的第一个全连接层的4096维输出（这里有点问题，论文里面说的是Pool 5，而我理解的Pool 5的输出时6×6×256的），输出为中心点坐标的平移量和宽高的缩放值。</li>
<li>定义IoU大于0.6的样本作为正样本用于训练。</li>
</ol>
<h1 id="Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）"><a href="#Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）" class="headerlink" title="Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）"></a>Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）</h1><ol>
<li>对AlexNet进行fine-tuning时采用的IoU阈值较小，被分为正样本的候选区域可能只包含部分物体，分类精度较低。</li>
<li>SVM训练时定义完全包含物体的候选区域才是正样本，分类精度较高。因此，使用SVM能够提高分类精度。</li>
</ol>
<h1 id="为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？"><a href="#为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？" class="headerlink" title="为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？"></a>为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？</h1><ol>
<li>Fine-tuning训练时，若IoU阈值设置过高，则可用于的训练样本较少（正样本减少，负样本为正样本的三倍），并且此时AlexNet已进行预训练，易由于样本过少而产生过拟合。因此，设置0.5的IoU阈值只是为了增加可用于训练的样本数量，避免过拟合。  </li>
<li>SVM训练时，为了达到进一步提高分类精度的目的，需要设置更为严格的正负样本分类规则。</li>
</ol>
<h1 id="回归器是如何进行边界框回归的？"><a href="#回归器是如何进行边界框回归的？" class="headerlink" title="回归器是如何进行边界框回归的？"></a>回归器是如何进行边界框回归的？</h1><h2 id="简答"><a href="#简答" class="headerlink" title="简答"></a>简答</h2><p>通过预测候选区域中心点坐标的平移量$\Delta x$，$\Delta y$和宽高的缩放值$S_w$，$S_h$来回归边界框。因此对于每个类别，需要4个回归器分别回归$\Delta x$，$\Delta y$，$S_w$，$S_h$，整个模型就包括20×4个回归器。</p>
<h2 id="详细"><a href="#详细" class="headerlink" title="详细"></a>详细</h2><p>定义$P=(P_x,P_y,P_w,P_h)$表示候选区域的中心坐标和宽高，$G=(G_x,G_y,G_w,G_h)$表示ground-truth的中心坐标和宽高。预测$d_*(P)$（$*$表示$x$，$y$，$w$，$h$，下同）得到平移量$\Delta x=P_wd_x(P)$，$\Delta y=P_hd_y(P)$和缩放值$S_w=exp(d_w(P))$，$S_h=exp(d_h(P))$，目标是使变换后的P与G更接近。<br>定义$\widehat{G}=(\widehat{G}_x,\widehat{G}_y,\widehat{G}_w,\widehat{G}_h)$表示变换后的$P$，其中：<br>$$\widehat{G}_x=P_wd_x(P)+P_x$$<br>$$\widehat{G}_y=P_hd_y(P)+P_y$$<br>$$\widehat{G}_w=P_wexp(d_w(P))$$<br>$$\widehat{G}_h=P_hexp(d_h(P))$$<br>回归器的输入是AlexNet提取的候选区域特征，表示为$\phi(P)$，令$d_*(P)=w^T_*\Phi(P)$，$w_*$就是需要学习的线性变换参数了，可以得到：<br>$$w^T_x\Phi(P)=d_x(P)=(\widehat{G}_x-P_x)/P_w$$<br>$$w^T_y\Phi(P)=d_y(P)=(\widehat{G}_y-P_y)/P_h$$<br>$$w^T_w\Phi(P)=d_w(P)=log(\widehat{G}_w/P_w)$$<br>$$w^T_h\Phi(P)=d_h(P)=log(\widehat{G}_h/P_h)$$<br>定义$t_*$为：<br>$$t_x=(G_x-P_x)/P_w$$<br>$$t_y=(G_y-P_y)/P_h$$<br>$$t_w=log(G_w/P_w)$$<br>$$t_h=log(G_h/P_h)$$<br>目标是使P的映射$\widehat{G}$尽量接近$G$，通过以下优化损失函数求解$w_*$：<br>$$w_*=\underset{\widehat{w}_*}{argmin}\sum(t_*^i-\widehat{w}_*^T\phi(P^i))^2+\lambda&#124;&#124;\widehat{w}_*&#124;&#124;^2$$<br>可通过最小二乘法或梯度下降求解该问题。由此也可以看出，对于每个类别，需要4个回归器分别回归$\Delta x$，$\Delta y$，$S_w$，$S_h$，整个模型就包括20×4个回归器。</p>
<h1 id="回归器为什么不直接预测平移量-Delta-x-和-Delta-y-的值，而是先预测-d-x-P-和-d-y-P-，然后分别乘以-P-w-和-P-h-，间接求出-Delta-x-和-Delta-y-？"><a href="#回归器为什么不直接预测平移量-Delta-x-和-Delta-y-的值，而是先预测-d-x-P-和-d-y-P-，然后分别乘以-P-w-和-P-h-，间接求出-Delta-x-和-Delta-y-？" class="headerlink" title="回归器为什么不直接预测平移量$\Delta x$和$\Delta y$的值，而是先预测$d_x(P)$和$d_y(P)$，然后分别乘以$P_w$和$P_h$，间接求出$\Delta x$和$\Delta y$？"></a>回归器为什么不直接预测平移量$\Delta x$和$\Delta y$的值，而是先预测$d_x(P)$和$d_y(P)$，然后分别乘以$P_w$和$P_h$，间接求出$\Delta x$和$\Delta y$？</h1><p>回归器的输入是候选区域的特征，而每个候选区域在提取特征后的大小时相同的，若是直接预测平移量$\Delta x$和$\Delta y$的值，那么对于两个内容相差无几，但是尺寸不一样的图像，会得到相同平移量，这显然是有问题的。而分别乘候选区域的宽高$P_w$和$P_h$相当于进行归一化，即尺寸大的候选区域预测的平移量大，尺寸小的候选区域的平移量小。</p>
<h1 id="回归器预测宽高的缩放值为什么要采用exp？"><a href="#回归器预测宽高的缩放值为什么要采用exp？" class="headerlink" title="回归器预测宽高的缩放值为什么要采用exp？"></a>回归器预测宽高的缩放值为什么要采用exp？</h1><p>保证预测值大于0.</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>优点：RCNN引入CNN提取特征，取代手工设计特征，并提升了检测速度；采用了迁移学习的思想，先在大数据集上对模型进行预训练，然后在目标数据集上面进行fine-tuning。</li>
<li>缺点：RCNN使用Selection Search提取2000个候选区域，不够精确；需要对每个候选区域单独提取特征，无法共享特征，且内存占用和耗时较大；训练过程分为三个阶段，繁琐且耗时较大。</li>
</ol>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型二：Fast RCNN</title>
    <url>/2020/07/01/FastRCNN/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于Fast RCNN模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">论文地址：Fast R-CNN</a><br><img src="/2020/07/01/FastRCNN/1.jpg" alt="Fast RCNN网络结构"></p>
<center><b>图1 Fast RCNN网络结构图</b></center>

<a id="more"></a>

<h1 id="简述一下Fast-RCNN测试时的检测流程？"><a href="#简述一下Fast-RCNN测试时的检测流程？" class="headerlink" title="简述一下Fast RCNN测试时的检测流程？"></a>简述一下Fast RCNN测试时的检测流程？</h1><ol>
<li>使用Selective Search在输入图像上提取约2000个候选区域。</li>
<li>将原始图像输入卷积网络，获得最后一个池化层之前的特征图（16倍下采样）。</li>
<li>对于每个候选区域，RoI pooling层将候选区域定位到特征图中的对应区域产生RoI，然后将每个RoI转化为相同尺寸（7×7）。</li>
<li>通过全连接层将RoI转化为一维向量，分别输入并行的分类器和回归器。分类器由一个全连接层和Softmax组成，对每一个RoI输出20+1个类别概率。回归器输出通过一个全连接层对每一个RoI输出20×4维向量，即所有类别下回归RoI的位置和大小。</li>
</ol>
<h1 id="描述一下RoI-pooling的工作原理？"><a href="#描述一下RoI-pooling的工作原理？" class="headerlink" title="描述一下RoI pooling的工作原理？"></a>描述一下RoI pooling的工作原理？</h1><p>先将候选区域定位到特征图中的对应区域产生RoI，然后将RoI划分为H×W的区域，然后分别取每个区域的最大值代替该区域，从而将RoI尺寸调整为H×W。</p>
<h1 id="两次坐标量化是指什么？"><a href="#两次坐标量化是指什么？" class="headerlink" title="两次坐标量化是指什么？"></a>两次坐标量化是指什么？</h1><ol>
<li>第一次量化时将候选区域映射到特征图上时，需要将候选区域坐标除以16并取整。</li>
<li>第二次量化是指RoI pooling时，需要将RoI划分为H×W个部分，对左上角坐标采用向下取整，对右下角坐标采用向上取整。两次量化操作会引入误差，Mask RCNN中会解决这一问题。</li>
</ol>
<h1 id="Fast-RCNN是如何训练的？"><a href="#Fast-RCNN是如何训练的？" class="headerlink" title="Fast RCNN是如何训练的？"></a>Fast RCNN是如何训练的？</h1><ol>
<li>以VGG16为例，先在ImageNet上训练一个1000类的分类网络。</li>
<li>修改预训练后的网络结构，将最后一个池化层替换为RoI pooling层；将最后一个全连接层替换为并行的分类器和回归器；网络输入替换为图像+候选区域集合。</li>
<li>将修改后的网络在Pascal VOC上进行fine-tuning，定义IoU大于0.5的为正样本，IoU为0.1-0.5之间的为负样本，每次迭代时包括2张图像，每张图像随机采样16个正样本和48个负样本用于训练；采样0.5概率的水平翻转进行数据增强。</li>
<li>采用分类损失和回归损失的联合组成的多任务损失函数进行训练。</li>
</ol>
<h1 id="Fast-RCNN的损失函数是如何构成的？"><a href="#Fast-RCNN的损失函数是如何构成的？" class="headerlink" title="Fast RCNN的损失函数是如何构成的？"></a>Fast RCNN的损失函数是如何构成的？</h1><h2 id="简答"><a href="#简答" class="headerlink" title="简答"></a>简答</h2><p>Fast RCNN采用多任务损失函数，由分类损失和回归损失联合组成。分类采用交叉熵损失函数，回归采用Smooth L1损失函数。</p>
<h2 id="详细"><a href="#详细" class="headerlink" title="详细"></a>详细</h2><p>Fast RCNN的多任务损失函数如下：<br>$$L(p,u,t^u,v)=L_{cls}(p,u)+\lambda [u\geq 1]L_{loc}(t^u,v)$$<br>其中，$L_{cls}(p,u)=-logp_u$表示真实分类u的概率$p_u$的对数损失。$\lambda$用于平衡分类损失和回归损失，通常取1。$[u\geq 1]$为指示函数，$u\geq 1$时取1否则取0，即当p为负样本时忽略回归损失。$L_{loc}(t^u,v)$为四个Smooth L1损失的和，分别是两个平移量和两个缩放值（具体参考上一篇关于RCNN的博客）。Smooth L1损失函数如下所示：<br>$$Smooth_{L1}(x)=\begin{cases} 0.5x^2 &amp; if&#124;x&#124;&lt;1 \\ &#124;x&#124;-0.5 &amp; otherwise \end{cases}$$<br>Smooth L1损失函数在x较大时（训练初期）采取L1损失函数形式，避免了L2损失在训练初期导数大的问题；在x较小（训练后期）时采取L2损失函数形式，避免了L1损失函数在训练后期导数大的问题。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>优点：Fast RCNN解决了RCNN的两大问题：①一次性提取特征然后对候选区域进行特征映射，实现特征共享，极大地节约了时间和空间消耗；②将RCNN的三个模型整合为一个模型，一次性进行分类和回归。</li>
<li>缺点：仍然存在与RCNN一样的问题，即使用Selective Search进行候选框提取。</li>
</ol>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型三：Faster RCNN</title>
    <url>/2020/07/15/FasterRCNN/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于Faster RCNN模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">论文地址：Faster R-CNN</a><br><img src="/2020/07/15/FasterRCNN/1.png" alt="Faster RCNN网络结构"></p>
<center><b>图1 Faster RCNN网络结构图</b></center>

<a id="more"></a>

<h1 id="简述一下Fast-RCNN测试时的检测流程？"><a href="#简述一下Fast-RCNN测试时的检测流程？" class="headerlink" title="简述一下Fast RCNN测试时的检测流程？"></a>简述一下Fast RCNN测试时的检测流程？</h1><ol>
<li>调整输入图像尺寸为16的倍数。</li>
<li>使用CNN（以VGG16为例）提取特征图。</li>
<li>RPN（Region Proposal Network）在特征图上生成一系列anchor box，并通过两个分支分别判断anchor box是否包含物体以及粗略位置修正。</li>
<li>将特征图和anchor boxes一起输入到RoI pooling层，与Fast RCNN一样，对于每个anchor boxes，RoI pooling层将候选区域定位到特征图中的对应区域产生RoI，然后将每个RoI转化为相同尺寸（7×7）。</li>
<li>经过两个全连接+ReLU层将RoI转化为一维向量，分别输入并行的分类器和回归器。分类器由一个全连接层和Softmax组成，对每一个RoI输出80+1个类别概率。回归器输出通过一个全连接层对每一个RoI输出80×4维向量，即所有类别下回归RoI的位置和大小。</li>
</ol>
<h1 id="Faster-RCNN相对于Fast-RCNN的主要改进在什么地方？"><a href="#Faster-RCNN相对于Fast-RCNN的主要改进在什么地方？" class="headerlink" title="Faster RCNN相对于Fast RCNN的主要改进在什么地方？"></a>Faster RCNN相对于Fast RCNN的主要改进在什么地方？</h1><ol>
<li>Faster RCNN不再使用Selective Search提取候选区域，而是采用卷积网络（RPN）产生候选框。</li>
<li>RPN网络在生成候选框后会对候选框进行筛选，只保留可能包含物体的候选框（～300个），为后续计算节约计算成本。</li>
</ol>
<h1 id="介绍一下RPN网络？"><a href="#介绍一下RPN网络？" class="headerlink" title="介绍一下RPN网络？"></a>介绍一下RPN网络？</h1><p><img src="/2020/07/15/FasterRCNN/3.png" alt="Faster RCNN网络结构"></p>
<center><b>图2 RPN网络结构图</b></center>

<ol>
<li>首先通过一个3×3的卷积进一步集中特征信息，然后在特征图上的每个特征点生成9个anchor box（三个尺度，三个比例），把生成的anchor boxes分别送入分类分支和回归分支。</li>
<li>对于分类分支，通过一个1×1卷积+Softmax输出每个anchor box存在物体的概率。</li>
<li>对于回归分支，通过一个1×1卷积输出每个anchor box的粗略位置估计，包括2个平移量（$\Delta x$，$\Delta y$）和两个缩放量($S_h$，$S_w$)，具体参考前面关RCNN的博客。</li>
<li>最后Proposal层根据分类和回归分支结果筛选候选框。首先根据回归结果修正候选框位置，然后根据分类结果筛选出前k（6000）个存在物体概率最高的候选框，并去除尺寸较小的和超出边界的候选框，再使用NMS剔除重叠候选框（0.7阈值），最后将筛选结果（约300个）送入RoI pooling层。</li>
</ol>
<h1 id="Faster-RCNN是如何训练的？"><a href="#Faster-RCNN是如何训练的？" class="headerlink" title="Faster RCNN是如何训练的？"></a>Faster RCNN是如何训练的？</h1><ol>
<li>交替训练（论文采用）：Faster RCNN可以看做时Fast RCNN + RPN，可以将Fast RCNN和RPN单独进行训练，但这两部分共享VGG16部分。<br>① 首先在ImageNet上面预训练VGG16；<br>② 使用①中的VGG16参数结合RPN进行训练；<br>③ 使用①中的VGG16参数组成Fast RCNN，并利用训练后的RPN网络生成候选框来训练Fast RCNN；<br>④ 使用③中的VGG16参数并结合RPN进行训练，VGG16参数不更新。<br>⑤ 使用③中的VGG16参数Fast RCNN，并利用④中的RPN网络生成候选框来训练Fast RCNN，VGG16参数不更新。</li>
<li>近似联合训练：将Faster RCNN整体进行训练，包括四个损失函数，RPN二分类损失，RPN回归损失，最后的多分类损失和回归损失。</li>
</ol>
<h1 id="Faster-RCNN的损失函数是如何构成的？"><a href="#Faster-RCNN的损失函数是如何构成的？" class="headerlink" title="Faster RCNN的损失函数是如何构成的？"></a>Faster RCNN的损失函数是如何构成的？</h1><ol>
<li>对于RPN训练，定义IoU最大或者IoU大于0.7的候选框为正样本，IoU小于0.3的候选框为负样本，其余候选框舍弃，每张图片随机采样128个正样本和128个负样本用于训练，若正样本过少，则增加负样本，保持样本总数为256。RPN的多任务损失函数为：<br>$$L({p_i},{t_i})=\frac {1}{N_{cls}}\sum_i L_{cls}(p_i,p_i^*)+\lambda \frac {1}{N_{reg}}\sum_i p_i^*L_{reg}(t_i,t_i^*)$$<br>其中，对于正样本$p_i^*=1$，否则为0。$L({p_i},{t_i})=-logp_i$表示第i个候选框含有物体的概率$p_i$的对数损失。$L_{loc}(t^u,v)$为四个Smooth L1损失的和，分别是两个平移量和两个缩放值（关于Smooth L1损失可参考上一篇关于Fast RCNN的博客）。</li>
<li>对于网络末端的分类器和回归器的训练，采用与Fast RCNN相同的损失函数。</li>
<li>实际上RPN的损失函数与Fast RCNN唯一的区别就在于一个是二分类，一个是多分类。此外，两者对于正负样本的划分有所区别。</li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>优点：Faster RCNN利用RPN生成候选框，舍弃了耗时的Selective Search方法，无论是检测速度和精度都得到了提升。</li>
<li>缺点：Faster RCNN的两阶段方法无法达到实时检测的效果。</li>
</ol>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux-File</title>
    <url>/2020/07/15/Linux-File/</url>
    <content><![CDATA[<p>本文总结了Linux系统中对文件属性和权限进行操作的常用命令。</p>
<a id="more"></a>

<h1 id="ls-l用于查看文件属性"><a href="#ls-l用于查看文件属性" class="headerlink" title="ls -l用于查看文件属性"></a><code>ls -l</code>用于查看文件属性</h1><pre><code>➜  ~ ls -l 
total 21776
drwxr-xr-x 26 dong dong     4096 11月 29  2019  anaconda3
drwxr-xr-x  8 dong dong     4096 7月  13 23:46  Clover</code></pre><p>每一个文件开头10个字符含义如下图：<br><img src="/2020/07/15/Linux-File/1.png" alt><br>第0位文件类型包括：<code>d</code>目录、<code>-</code>文件及其他（<code>l</code>、<code>b</code>、<code>c</code>），第1-3位表示该文件所有者的权限，第4-6位表示所有者同组用户的权限，第7-9位表示其他用户的权限。<code>r</code>读、<code>w</code>写、<code>x</code>执行（execute）表示拥有对应权限，<code>-</code>表示没有该权限。</p>
<h1 id="chown-R-属主名-文件或目录用于更改文件属主"><a href="#chown-R-属主名-文件或目录用于更改文件属主" class="headerlink" title="chown [-R] 属主名 文件或目录用于更改文件属主"></a><code>chown [-R] 属主名 文件或目录</code>用于更改文件属主</h1><p>加上参数<code>-R</code>表示递归更改文件属主。</p>
<h1 id="chgrp-R-属组名-文件或目录用于更改文件属组"><a href="#chgrp-R-属组名-文件或目录用于更改文件属组" class="headerlink" title="chgrp [-R] 属组名 文件或目录用于更改文件属组"></a><code>chgrp [-R] 属组名 文件或目录</code>用于更改文件属组</h1><p>加上参数<code>-R</code>表示递归更改文件属组。</p>
<h1 id="chmod-R-xyz-文件或目录用于更改文件的9个权限"><a href="#chmod-R-xyz-文件或目录用于更改文件的9个权限" class="headerlink" title="chmod [-R] xyz 文件或目录用于更改文件的9个权限"></a><code>chmod [-R] xyz 文件或目录</code>用于更改文件的9个权限</h1><p>加上参数<code>-R</code>表示递归更改文件权限。<br><code>xyz</code>表示要设置的权限数字，每个权限数字为3个权限分数之和，各权限分数对照如下：</p>
<ul>
<li><code>r</code>：4</li>
<li><code>w</code>：2</li>
<li><code>x</code>：1</li>
</ul>
<p>例如<code>7=rwx</code>，<code>0=---</code>，<code>drwxr-xr-x</code>的权限数字为<code>755</code>。</p>
<p>或者可以使用<code>chmod u=rwx,g=rx,o=r 文件名</code>的命令来设定文件的权限，具体如下表所示：</p>
<table>
<thead>
<tr>
<th>chmod</th>
<th>u</th>
<th>+（加入）</th>
<th>r</th>
<th>文件或目录</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>g</td>
<td>-（除去）</td>
<td>w</td>
<td></td>
</tr>
<tr>
<td></td>
<td>o</td>
<td>=（设定</td>
<td>x</td>
<td></td>
</tr>
<tr>
<td></td>
<td>a</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Linux基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统知识——进程线程</title>
    <url>/2020/07/16/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B/</url>
    <content><![CDATA[<p>本文总结了进程与线程的基础知识。</p>
<a id="more"></a>

<h1 id="并发与并行"><a href="#并发与并行" class="headerlink" title="并发与并行"></a>并发与并行</h1><p>并发是指一段时间内在单核CPU上交替运行多个程序。</p>
<p>并行是指同一时刻在多核CPU上同时运行多个程序。</p>
<h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><p>进程是<strong>资源分配</strong>的基本单位。</p>
<p>进程间数据不共享，创建和销毁的开销较大。</p>
<h1 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h1><p>线程时<strong>独立调度</strong>的基本单位。</p>
<p>一个进程至少有一个线程，称为主线程，其他为子线程。</p>
<p>一个进程中可以有多个线程，它们共享进程资源。</p>
<h1 id="孤儿进程"><a href="#孤儿进程" class="headerlink" title="孤儿进程"></a>孤儿进程</h1><p>一个父进程退出，而它的子进程还在运行，这些子进程称为孤儿进程。孤儿进程将被init进程（进程号为1）所收养，并由init进程对它们完成状态收集工作。孤儿进程不会对系统造成伤害。</p>
<h1 id="僵尸进程"><a href="#僵尸进程" class="headerlink" title="僵尸进程"></a>僵尸进程</h1><p>如果子进程退出，而父进程没有调用wait()或waitpid()，那么子进程的进程描述符仍然存在系统中，这些子进程称为僵尸进程。系统能使用的进程号是有限的，若僵尸进程过多，可能导致系统无法产生新的进程。通过杀死父进程可以将僵尸进程变成孤儿进程，从而被init进程收养，只有init进程就会释放所有僵尸进程占有的资源，从而结束僵尸进程。</p>
<h1 id="进程状态的切换"><a href="#进程状态的切换" class="headerlink" title="进程状态的切换"></a>进程状态的切换</h1><p>进程有三个状态：</p>
<ul>
<li>就绪（ready）：等待被调度（等待CPU时间）</li>
<li>运行（running）</li>
<li>阻塞（waiting）：等待资源（除CPU时间外的资源）</li>
</ul>
<p>就绪和运行可以相互切换，其他都是单向切换。</p>
<h1 id="进程调度算法"><a href="#进程调度算法" class="headerlink" title="进程调度算法"></a>进程调度算法</h1><h2 id="批处理系统"><a href="#批处理系统" class="headerlink" title="批处理系统"></a>批处理系统</h2><ol>
<li><p><strong>先来先服务：</strong>非抢占式，有利于长作业，不利于短作业。</p>
</li>
<li><p><strong>短作业优先：</strong>非抢占式，长作业可能永远得不到调度。</p>
</li>
<li><p><strong>最短剩余时间优先：</strong>抢占式，按剩余运行时间的顺序进行调度。</p>
</li>
</ol>
<h2 id="交互式系统"><a href="#交互式系统" class="headerlink" title="交互式系统"></a>交互式系统</h2><ol>
<li><strong>时间片轮转：</strong>所有进程按先来先服务的原则排成队列，每次调度时把一个时间片分配给队首进程，队首进程时间片结束后被送到队尾。</li>
<li><strong>优先级调度：</strong>每个进程分配一个优先级，按优先级进行调度，为了避免低优先级进程永远得不到调度，可以随时间增加等待进程的优先级。</li>
<li><strong>多级反馈队列：</strong>设置多个时间片大小不同的队列，进程若在第一个队列结束时间片后未执行完毕，则被送到下一个队列末尾。</li>
</ol>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://cyc2018.github.io/CS-Notes/#/" target="_blank" rel="noopener">CS-Notes</a></p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>字节跳动安卓客户端面试题集</title>
    <url>/2020/07/17/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%AE%A2%E6%88%B7%E7%AB%AF%E9%9D%A2%E8%AF%95%E9%A2%98%E9%9B%86/</url>
    <content><![CDATA[<p>本文搜集整理了网络上关于字节跳动客户端面试题。</p>
<a id="more"></a>

<ul>
<li><input disabled type="checkbox"> 线程同步的方式</li>
<li><input disabled type="checkbox"> 死锁产生的条件？如何避免和解决？</li>
<li><input disabled type="checkbox"> 为什么有了进程还要线程？</li>
<li><input disabled type="checkbox"> HTTP和HTTPS的区别？HTTPS连接建立的过程？如果服务端也需要客户端传证书，应该是连接建立的哪个阶段？HTTP用的是TCP还是UDP？</li>
<li><input disabled type="checkbox"> TCP和UDP的区别？应用场景？</li>
<li><input disabled type="checkbox"> TCP的拥塞控制</li>
<li><input disabled type="checkbox"> 分段和分页</li>
<li><input disabled type="checkbox"> 进程调度算法</li>
<li><input disabled type="checkbox"> 进程线程的区别与联系？进程之间的通信方式？线程之间通信方式？</li>
<li><input disabled type="checkbox"> 三次握手</li>
<li><input disabled type="checkbox"> SSL握手过程？第一次握手如何加密？第二次握手如何加密？对称加密？非对称加密？加密过程？</li>
<li><input disabled type="checkbox"> 信号量与互斥量的区别？</li>
<li><input disabled type="checkbox"> wait()和sleep()的区别？</li>
<li><input disabled type="checkbox"> 设计模式？</li>
<li><input disabled type="checkbox"> JAVA：LinkedList与ArrayList？HashMap扩容？ConcurrentHashMap？创建对象的几种方式？</li>
<li><input disabled type="checkbox"> JVM内存模型？</li>
<li><input disabled type="checkbox"> 活动的生命周期？活动的启动模式？Handler源码？</li>
<li><input disabled type="checkbox"> 在浏览器输入网址敲回车后经历了什么？a)三次握手；b)https的加密流程；c)对称加密与非对称加密原理（RSA、AES）</li>
<li><input disabled type="checkbox"> DNS原理</li>
</ul>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>字节跳动</tag>
        <tag>JAVA</tag>
        <tag>安卓客户端</tag>
        <tag>题集</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络——网络层</title>
    <url>/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E7%BD%91%E7%BB%9C%E5%B1%82/</url>
    <content><![CDATA[<p>本文整理计算机网络中运输层的主要知识点。</p>
<a id="more"></a>

<p><img src="/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E7%BD%91%E7%BB%9C%E5%B1%82/6.png" alt></p>
<p>网络层向上只提供尽最大努力交付的数据报服务，不提供服务质量的承诺。</p>
<h1 id="网际协议IP"><a href="#网际协议IP" class="headerlink" title="网际协议IP"></a>网际协议IP</h1><p>ARP协议：从网络层使用的IP地址，解析出数据链路层使用的硬件地址。</p>
<h2 id="IP数据报的格式"><a href="#IP数据报的格式" class="headerlink" title="IP数据报的格式"></a>IP数据报的格式</h2><p><img src="/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E7%BD%91%E7%BB%9C%E5%B1%82/1.png" alt></p>
<p>20字节固定长度：</p>
<ul>
<li>版本：占4位，指IP协议的版本，通信双方版本必须一致。IPv4或IPv6。</li>
<li>首部长度：占4位，单位是4字节，表示首部最大长度为60字节，当首部长度不是4字节的整数倍时，必须利用填充字段加以填充。</li>
<li>区分服务：占1字节，用来获得更好的服务，一般不用。</li>
<li>总长度：占2字节，指首部和数据的总长度。</li>
<li>标识：占2字节，在数据报过长而发生分片时，相同数据报的不同分片具有相同标识符。</li>
<li>标志：占3位，第一位为1表示后面还有分片，第二位为0表示不能分片，第三位无意义。</li>
<li>片偏移：占13位，单位为8字节，表示分片在原数据报中的相对位置。</li>
<li>生存时间：占1字节，数据报在网络中的寿命。</li>
<li>协议：占1字节，指出此数据报携带的数据是使用何种协议。</li>
<li>首部检验和：占2字节，检验数据报的首部。</li>
<li>原地址：占4字节。</li>
<li>目的地址：占4字节。</li>
</ul>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>网络层</tag>
      </tags>
  </entry>
  <entry>
    <title>计算机网络——运输层协议</title>
    <url>/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E8%BF%90%E8%BE%93%E5%B1%82/</url>
    <content><![CDATA[<p>本文整理计算机网络中运输层的主要知识点。</p>
<a id="more"></a>

<p><img src="/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E8%BF%90%E8%BE%93%E5%B1%82/6.png" alt></p>
<p>TCP和UDP是TCP/IP运输层的两个主要协议。</p>
<h1 id="用户数据报协议UDP（User-Datagram-Protocol）"><a href="#用户数据报协议UDP（User-Datagram-Protocol）" class="headerlink" title="用户数据报协议UDP（User Datagram Protocol）"></a>用户数据报协议UDP（User Datagram Protocol）</h1><ol>
<li><p>传送数据前不需要建立连接。</p>
</li>
<li><p>尽最大努力交付。</p>
</li>
<li><p>面向报文，对应用程序交下来的报文，在添加UDP首部后就向下交付给IP层。</p>
</li>
<li><p>没有拥塞控制。</p>
</li>
<li><p>支持一对一、一对多、多对一、多对多通信。</p>
</li>
<li><p>8字节首部，开销小：源端口、目的端口、长度、检验和，每个字段都是两个字节。</p>
<p><img src="/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E8%BF%90%E8%BE%93%E5%B1%82/1.png" alt></p>
</li>
</ol>
<h1 id="传输控制协议TCP（Transmission-Control-Protocol）"><a href="#传输控制协议TCP（Transmission-Control-Protocol）" class="headerlink" title="传输控制协议TCP（Transmission Control Protocol）"></a>传输控制协议TCP（Transmission Control Protocol）</h1><ol>
<li><p>传送数据前必须建立TCP连接。</p>
</li>
<li><p>每一条TCP连接只能是点对点（一对一）。</p>
</li>
<li><p>可靠交付。</p>
</li>
<li><p>全双工通信（双向同时通信）。</p>
</li>
<li><p>面向字节流。</p>
</li>
<li><p>最小20字节首部包括：</p>
<p><img src="/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E8%BF%90%E8%BE%93%E5%B1%82/2.png" alt></p>
<ul>
<li>源端口和目标端口：各占2字节。</li>
<li>序号：占4字节，对字节流进行编号，如序号为301，表示第一个字节的编号为301，若携带数据长度为100字节，则下一个报文段的序号应该为401。4字节=32位，可对4GB数据进行编号。</li>
<li>确认号：占4字节，期望收到下一个报文段的序号。如服务器正确收到客户的一个序号为501的报文段，携带数据长度为200字节，因此服务器期望下一个报文段的序号为701，即发给客户的确认报文段中确认号为701。</li>
<li>数据偏移：占4位，指TCP首部的长度。单位是4字节，也就是说TCP首部最大长度为60字节。</li>
<li>保留：占6位，保留，目前置0。</li>
<li>紧急URG：占1位，为1时表示此报文段中有紧急数据，发送方应优先传送。</li>
<li>确认ACK：占1位，为1时确认号字段有效，TCP连接建立后所有报文段必须把ACK置1。</li>
<li>推送PSH：占1位，为1时接收方会尽快交付给接收进程。</li>
<li>复位RST：占1位，RST=1表示连接中存在严重差错，必须重新建立连接，或用于拒绝非法报文，或拒绝打开一个连接。</li>
<li>同步SYN：占1位，建立连接时用于同步序号。SYN=1，ACK=0表示连接请求报文段，若对方同意，则响应报文中SYN=1，ACK=1。</li>
<li>终止FIN：占1位，用于释放一个连接。FIN=1表示此报文段的发送方要求释放连接。</li>
<li>窗口：占2字节，告诉对方自己能接收的数据流字节长度。</li>
</ul>
</li>
</ol>
<h2 id="TCP的可靠传输"><a href="#TCP的可靠传输" class="headerlink" title="TCP的可靠传输"></a>TCP的可靠传输</h2><p>TCP使用超时重传来实现可靠传输，若在发送报文段后超时时间内没有收到确认，则重传这个报文段。</p>
<h2 id="TCP的滑动窗口协议"><a href="#TCP的滑动窗口协议" class="headerlink" title="TCP的滑动窗口协议"></a>TCP的滑动窗口协议</h2><p>发送方和接收方各有一个窗口用于缓存数据。发送缓存用于暂时存放准备发送的数据和已发送而尚未确认的数据。接收缓存用于暂时存放按序到达但尚未被接收进程读取的数据和未按序到达的数据。</p>
<h2 id="TCP的流量控制"><a href="#TCP的流量控制" class="headerlink" title="TCP的流量控制"></a>TCP的流量控制</h2><p>流量控制时为了控制发送方发送速率，保证接收方来得及接收。</p>
<p>接收方可以通过确认报文中的窗口字段来控制发送方的窗口大小，从而影响发送方的发送速率。</p>
<h2 id="TCP的拥塞控制方法"><a href="#TCP的拥塞控制方法" class="headerlink" title="TCP的拥塞控制方法"></a>TCP的拥塞控制方法</h2><p><img src="/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E8%BF%90%E8%BE%93%E5%B1%82/3.png" alt></p>
<ol>
<li>慢开始：由小到大逐渐增大发送窗口（拥塞窗口），每收到一个确认，窗口长度（cwnd）×2，cwnd超过阈值ssthresh时，停止使用慢开始算法而改用拥塞避免算法（图中点①）。若出现超时，则设置ssthresh=cwnd/2，并重新执行慢开始算法（图中点②）。</li>
<li>拥塞避免：让发送窗口缓慢地增大，每收到一个确认，把cwnd加1。</li>
<li>快重传：接受方如果收到失序的报文段，要立即发出前一个报文段的重复确认，发送方只要一连收到3个重复确认，应立即执行快重传（图中点④），重新发送失序报文段。</li>
<li>快恢复：若发送方一连收到3个重复确认，知道只是丢失了个别字段而不是堵塞，于是不重新启动慢开始算法，而是执行快恢复算法，调整ssthresh=cwnd/2，同时设置cwnd=cwnd/2，并开始执行拥塞避免算法（图中点⑤）。</li>
</ol>
<h2 id="TCP的连接"><a href="#TCP的连接" class="headerlink" title="TCP的连接"></a>TCP的连接</h2><p>TCP连接的端点为套接字（socket）或插口：</p>
<p>$$ 套接字socket=（IP地址：端口号） $$</p>
<p>每一条TCP连接由两个套接字确定。发起连接的进程称为客户（client），被动等待连接的进程称为服务器（server）。</p>
<h3 id="TCP的连接建立（三次握手，三报文握手）"><a href="#TCP的连接建立（三次握手，三报文握手）" class="headerlink" title="TCP的连接建立（三次握手，三报文握手）"></a>TCP的连接建立（三次握手，三报文握手）</h3><p><img src="/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E8%BF%90%E8%BE%93%E5%B1%82/4.png" alt></p>
<p>如图所示，TCP建立连接时需要在客户和服务器之间交换三个TCP报文段（客户请求，服务器确认，客户确认）。</p>
<ol>
<li>首先服务器端处于监听状态，等待客户的连接请求。</li>
<li>客户向服务器端发送连接请求报文。</li>
<li>服务器收到连接请求报文，如果同意连接，则向客户发送连接确认报文。</li>
<li>客户收到服务器的连接确认报文后，向服务器发出确认，且报文段可以携带数据。</li>
<li>服务器收到确认后，建立连接。</li>
</ol>
<p>第三次握手的原因：防止失效的连接请求到达服务器，让服务器错误打开连接。若客户的某个连接请求在网络中滞留时间过长，客户会重新请求连接，但滞留的连接请求还是会到达服务器，如果不进行第三次握手，那么服务器会打开两个连接。进行第三次握手使得最终连接权在客户。</p>
<h3 id="TCP的连接释放（四次挥手，四报文握手）"><a href="#TCP的连接释放（四次挥手，四报文握手）" class="headerlink" title="TCP的连接释放（四次挥手，四报文握手）"></a>TCP的连接释放（四次挥手，四报文握手）</h3><p><img src="/2020/07/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94%E8%BF%90%E8%BE%93%E5%B1%82/5.png" alt></p>
<p>TCP连接释放过程如图所示（客户释放，服务器确认，服务器释放，客户确认）。</p>
<ol>
<li>客户的进程向其TCP发出连接释放报文段，并停止发送数据，主动关闭TCP连接。</li>
<li>客户把连接释放报文段的FIN置1并发送给服务器，客户进入终止等待1状态，等待服务器的确认。</li>
<li>服务器收到连接释放报文段后发出确认，然后进入关闭等待状态。服务器通知进程，此时客户到服务器的连接释放了，但是服务器到客户的连接还未关闭。</li>
<li>客户收到服务器的确认后，进入终止等待2状态，继续等待服务器的连接释放报文。</li>
<li>若服务器没有要向客户端发送的数据，则向客户发出连接释放报文，必须使FIN=1，进入最后确认状态。</li>
<li>客户收到服务器的连接释放报文后，对此发出确认，进入时间等待状态，等待2MSL（最长报文寿命）后释放连接。</li>
<li>服务器收到确认报文后释放连接。</li>
</ol>
<p>客户等待2MSL的原因：</p>
<ol>
<li>为了保证客户的最后一个确认报文到达服务器，如果服务器没收到客户的确认报文，则会再次发送连接释放报文。</li>
<li>为了保证本次连接的所有报文已经从网络中消失。</li>
</ol>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>运输层</tag>
      </tags>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型四：YOLOv1</title>
    <url>/2020/07/17/yolov1/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于YOLOv1模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1506.02640" target="_blank" rel="noopener">论文地址：You Only Look Once: Unified, Real-Time Object Detection</a></p>
<p><img src="/2020/07/17/yolov1/1.png" alt></p>
<center><b>图1 YOLOv1网络结构图</b></center>

<a id="more"></a>

<h1 id="简述一下YOLOv1测试时的检测流程？"><a href="#简述一下YOLOv1测试时的检测流程？" class="headerlink" title="简述一下YOLOv1测试时的检测流程？"></a>简述一下YOLOv1测试时的检测流程？</h1><ol>
<li>调整输入图像尺寸为448×448×3。</li>
<li>经过24层卷积输出7×7×1024特征图（64×下采样），再通过一个全连接层输出4096维特征，最后经过一个全连接层输出S×S×30的特征图。（Fast YOLO包括9个卷积）</li>
<li>通过NMS筛选最终结果，NMS的<code>score=某个类别的概率×置信度</code>。</li>
</ol>
<h1 id="YOLOv1的创新点有哪些？"><a href="#YOLOv1的创新点有哪些？" class="headerlink" title="YOLOv1的创新点有哪些？"></a>YOLOv1的创新点有哪些？</h1><ol>
<li>将检测问题转化为回归问题，同时输出预测框的坐标信息和类别概率。</li>
<li>没有提取候选区域的过程。</li>
</ol>
<h1 id="网络最后输出7×7×30特征图的含义？"><a href="#网络最后输出7×7×30特征图的含义？" class="headerlink" title="网络最后输出7×7×30特征图的含义？"></a>网络最后输出7×7×30特征图的含义？</h1><p>YOLOv1将图片划分为7×7个格子，每个格子负责预测中心点落在该格子区域的物体，每个格子预测两个矩形框。每个格子最后输出30个预测值，包括两个矩形框的位置信息<code>(x, y, w, h)</code>和置信度，以及20个类别的概率。</p>
<h1 id="YOLOv1是如何训练的？"><a href="#YOLOv1是如何训练的？" class="headerlink" title="YOLOv1是如何训练的？"></a>YOLOv1是如何训练的？</h1><ol>
<li><p>在ImageNet上对前20个卷积层进行预训练，具体地，训练时输入尺寸为224×224，网络结构为前20个卷积层+平均池化层+1000全连接层。</p>
</li>
<li><p>添加4个卷积层和两个全连接层，第一个全连接层后添加一个0.5的dropout层。输入尺寸为448×448，激活函数采用Leaky-ReLU（最后一层使用线性激活函数），优化方法采用0.9的Momentum，数据增强采用随机缩放，随机截取，随机调整曝光度和饱和度。</p>
</li>
<li><p>Loss函数由五个平方和误差（L2损失）组成：</p>
<p><img src="/2020/07/17/yolov1/2.png" alt></p>
<p>其中$\lambda_{coord}=5$，$\lambda_{noobj}=0.5$，由于含有物体的格子较少，因此加大含有物体的格子的损失贡献。</p>
<ul>
<li>第一行为与ground-truth的IoU较大的预测框的中心点坐标损失；</li>
<li>第二行为与ground-truth的IoU较大的预测框的宽高损失，取根号是为了消除大尺寸框与小尺寸框之间的差异；</li>
<li>第三行和第四行是两个预测框的置信度损失，若格子不含物体则置信度为0，否则为IoU；</li>
<li>第五行为格子的类别损失。</li>
</ul>
<p>对于有物体的格子，需要计算分类损失，两个框的置信度损失，IoU较大的框的位置损失。</p>
<p>对于没物体的格子，只需要计算两个框的置信度损失。</p>
</li>
</ol>
<h1 id="YOLOv1回归的坐标值是什么含义？"><a href="#YOLOv1回归的坐标值是什么含义？" class="headerlink" title="YOLOv1回归的坐标值是什么含义？"></a>YOLOv1回归的坐标值是什么含义？</h1><p>$(x,y)$是格子左上角坐标的偏移值（0-1），$(w,h)$预测的是预测框的宽高与原始图像宽高的比值（0-1）。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>YOLOv1具有运行速度快，背景误检率等优点，但由于其设置，每个格子最多只能检测一个物体，导致易漏检中心距离近的物体，召回率低，位置准确性较差。</p>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Python基础——Python 2.x与Python 3.x的主要区别</title>
    <url>/2020/07/17/Python%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%942-x%E4%B8%8E3-x%E7%9A%84%E4%B8%BB%E8%A6%81%E5%8C%BA%E5%88%AB/</url>
    <content><![CDATA[<p>本文总结了Python 2.x与Python 3.x的主要区别。</p>
<a id="more"></a>

<h1 id="print函数"><a href="#print函数" class="headerlink" title="print函数"></a>print函数</h1><p>print()函数取代print语句。</p>
<h1 id="Unicode"><a href="#Unicode" class="headerlink" title="Unicode"></a>Unicode</h1><p>Python 2.x默认使用ASCII编码，不能直接输出中文，变量命名只能用英文。</p>
<p>Python 3.x默认使用UTF-8编码，可以直接输出中文，可以使用中文变量名。</p>
<h1 id="除法运算"><a href="#除法运算" class="headerlink" title="除法运算/"></a>除法运算<code>/</code></h1><p>Python 2.x，整数相除结果为整数，浮点数相除为浮点数。</p>
<p>Python 3.x，结果始终是浮点数。</p>
<h1 id="打开文件"><a href="#打开文件" class="headerlink" title="打开文件"></a>打开文件</h1><p>Python 2.x可以使用file(…)或者open(…)。</p>
<p>Python 3.x只能使用open(…)。</p>
<h1 id="xrange函数"><a href="#xrange函数" class="headerlink" title="xrange函数"></a>xrange函数</h1><p>Python 3.x取消了xrange函数，使用range函数完全代替。</p>
<h1 id="八进制字面量表示"><a href="#八进制字面量表示" class="headerlink" title="八进制字面量表示"></a>八进制字面量表示</h1><p>Python 2.x可以用01000或0o1000表示八进制512。</p>
<p>Python 3.x只可以使用0o1000。</p>
<h1 id="不等运算符"><a href="#不等运算符" class="headerlink" title="不等运算符"></a>不等运算符</h1><p>Python 2.x可以用<code>!=</code>或<code>&lt;&gt;</code>。</p>
<p>Python 3.x只能使用<code>!=</code>。</p>
<h1 id="Python-3-x使用更加严格的缩进"><a href="#Python-3-x使用更加严格的缩进" class="headerlink" title="Python 3.x使用更加严格的缩进"></a>Python 3.x使用更加严格的缩进</h1><p>Python 2.x中允许tab和space共存。</p>
<p>Python 3.x只能单独使用tab或者space。</p>
<h1 id="去掉了repr表达式"><a href="#去掉了repr表达式" class="headerlink" title="去掉了repr表达式"></a>去掉了repr表达式</h1><p>Python 2.x中反引号``相当于repr函数的作用。</p>
<p>Python 3.x中去掉了``的写法，只允许使用repr函数。</p>
<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><p>Python 3.x去掉了long类型，只有一种整形——int。新增了bytes类型。</p>
<h1 id="input和raw-input函数"><a href="#input和raw-input函数" class="headerlink" title="input和raw_input函数"></a>input和raw_input函数</h1><p>Python 2.x中raw_input会将所有输入数据当做字符串，返回值为字符串；而input输入时必须是一个合法的Python表达式。</p>
<p>Python 3.x只能使用input。</p>
<h1 id="map、filter和reduce"><a href="#map、filter和reduce" class="headerlink" title="map、filter和reduce"></a>map、filter和reduce</h1><p>Python 2.x中map，filter和reduce是内置函数，返回结果为列表。</p>
<p>Python 3.x中map和filter变成了类，返回结果为可迭代对象。reduce从全局挪到了functool模块中。</p>
<h1 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h1><p>捕获异常的语法由<code>except exc, var</code>改为<code>except exc as var</code>。</p>
<p>Python 2.x中所有类型的对象都可以被抛出；Python 3.x中只有继承自BaseException的对象才可以被抛出。</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型五：YOLOv2</title>
    <url>/2020/07/18/yolov2/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于YOLOv2模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1612.08242" target="_blank" rel="noopener">论文地址：YOLO9000: Better, Faster, Stronger</a><br><img src="/2020/07/18/yolov2/1.png" alt></p>
<center><b>图1 YOLOv2与YOLOv1技巧对比图</b></center>

<a id="more"></a>

<h1 id="YOLOv2采用了哪些技巧？"><a href="#YOLOv2采用了哪些技巧？" class="headerlink" title="YOLOv2采用了哪些技巧？"></a>YOLOv2采用了哪些技巧？</h1><ol>
<li>BN层代替Dropout层。</li>
<li>高分辨率的预训练：预训练时，先使用224×224的输入尺寸训练160个epochs，再使用448×448的输入尺寸训练10个epochs。</li>
<li>使用anchor boxes预测边界框：输入尺寸调整为416×416，输出特征图尺寸为13×13(32倍下采样），准确率下降但是召回率提高。</li>
<li>K-means聚类生成anchor box尺寸：聚类的距离函数为$d(box,centroid)=1-IoU(box,centroid)$，若采用欧氏距离会使得尺寸大的框误差也大。实验表明k=5时，在召回率和模型复杂的直接平衡性较好。</li>
<li>直接位置预测：预测相对锚框所属格子左上角坐标的偏移量$(b_x,b_y)$，以及与anchor box宽高的e的指数比例$(b_w,b_h)$，比RCNN系列采用的位置预测方法更易学习。</li>
<li>细粒度特征：类似ResNet，将最后一个26×26的特征图连接到最后一个13×13的特征图上。具体地，首先通过1×1卷积将26×26×512减低通道数为26×26×64，再拆分成4个13×13×64并拼接为13×13×256，然后与13×13×1024进行连接生成13×13×(256+1024)的特征图。</li>
<li>多尺度训练：每隔10个batch随机从{320,352,384,…,608}中选择一个尺度作为输入图像的尺寸。</li>
</ol>
<h1 id="YOLOv2的网络结构有哪些改进？"><a href="#YOLOv2的网络结构有哪些改进？" class="headerlink" title="YOLOv2的网络结构有哪些改进？"></a>YOLOv2的网络结构有哪些改进？</h1><p><img src="/2020/07/18/yolov2/2.png" alt></p>
<center><b>图2 Darknet19网络结构图</b></center>

<ol>
<li><p>预训练时，如图2所示，Darknet 19包含19个卷积层（YOLOv1网络包含24个卷积层和2个全连接层）。</p>
<p><img src="/2020/07/18/yolov2/3.png" alt></p>
<center><b>图2 YOLOv2网络结构图</b></center>
</li>
<li><p>用于检测时，如图3所示，首先添加三个3×3的卷积，然后输出特征图与细粒度特征中提到的跳跃连接进行拼接，再通过一个3×3卷积调整通道数，最后通过一个1×1卷积输出13×13×125的检测结果，对于13×13个格子，每个格子输出5×25维向量，其中5表示每个格子有五个anchor boxes，25包括20个类别概率，4个位置预测和1个置信度。</p>
</li>
<li><p>预训练时，先使用224×224的输入尺寸训练160个epochs，再使用448×448的输入尺寸训练10个epochs。</p>
</li>
</ol>
<h1 id="YOLOv2的样本是如何设置的？"><a href="#YOLOv2的样本是如何设置的？" class="headerlink" title="YOLOv2的样本是如何设置的？"></a>YOLOv2的样本是如何设置的？</h1><p>类似与YOLOv1，对于一个ground-truth，包含其中心点的格子的5个anchor boxes负责预测该物体框，只有与ground-truth的IoU最大的anchor box会用于计算loss。YOLOv2不再对宽高取根号。与ground-truth的IoU最大或大于0.6的anchor box为正样本。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/zijin0802034/article/details/77097894" target="_blank" rel="noopener">https://blog.csdn.net/zijin0802034/article/details/77097894</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/35325884" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35325884</a></p>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型六：YOLOv3</title>
    <url>/2020/07/18/yolov3/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于YOLOv3模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1804.02767" target="_blank" rel="noopener">论文地址：YOLOv3: An Incremental Improvement</a><br><img src="/2020/07/18/yolov3/1.png" alt></p>
<center><b>图1 Darknet-53网络结构图</b></center>

<a id="more"></a>

<h1 id="YOLOv3在有哪些主要改进？"><a href="#YOLOv3在有哪些主要改进？" class="headerlink" title="YOLOv3在有哪些主要改进？"></a>YOLOv3在有哪些主要改进？</h1><ol>
<li><p>Darknet-53代替Darknet-19，使用了残差模块，步长为2的卷积层代替池化层进行下采样。</p>
<p><img src="/2020/07/18/yolov3/3.jpg" alt></p>
<center><b>图2 YOLOv3网络结构图</b></center>
</li>
<li><p>采用了多尺度结构，在获得32倍下采样特征图后，又开始对特征图进行上采样，并与前面的16倍下采样特征图连接，然后继续对特征图进行上采样，并与前面的8倍下采样特征图连接。分别在三个尺度（8,16,32）的特征图上进行检测，输出分别为13×13×3×(4+1+80)，26×26×3×(4+1+80)，52×52×3×(4+1+80)。</p>
</li>
<li><p>使用独立的logistic分类器（sigmoid）代替softmax分类器进行分类。</p>
</li>
</ol>
<h1 id="YOLOv3在anchor-boxes方面有什么改进？"><a href="#YOLOv3在anchor-boxes方面有什么改进？" class="headerlink" title="YOLOv3在anchor boxes方面有什么改进？"></a>YOLOv3在anchor boxes方面有什么改进？</h1><p>由于YOLOv3采用了多尺度预测，anchor boxes的设计也做了相应改进。同样是使用k-means进行聚类，YOLOv3聚类了3个尺度，每个尺度聚类了3种尺寸的anchor boxes。</p>
<h1 id="YOLOv3的损失函数有哪些改进？"><a href="#YOLOv3的损失函数有哪些改进？" class="headerlink" title="YOLOv3的损失函数有哪些改进？"></a>YOLOv3的损失函数有哪些改进？</h1><p>置信度和类别用交叉熵损失替换了平方和损失。为了提高小物体的损失贡献，位置回归损失会乘以系数(2-w×h)。</p>
<p><img src="/2020/07/18/yolov3/2.png" alt></p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/leonardohaig/article/details/90346325" target="_blank" rel="noopener">https://blog.csdn.net/leonardohaig/article/details/90346325</a></p>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型七：SSD</title>
    <url>/2020/07/19/SSD/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于SSD模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1512.02325" target="_blank" rel="noopener">论文地址：Single Shot MultiBox Detector</a></p>
<p><img src="/2020/07/19/SSD/1.png" alt></p>
<center><b>图1 SSD与YOLOv1网络结构对比图</b></center>

<a id="more"></a>

<h1 id="SSD有哪些主要特点？"><a href="#SSD有哪些主要特点？" class="headerlink" title="SSD有哪些主要特点？"></a>SSD有哪些主要特点？</h1><ol>
<li><p>类似YOLO，将检测转化为回归，一次性完成定位与回归。</p>
</li>
<li><p>类似Faster RCNN，使用了先验框。</p>
<p><img src="/2020/07/19/SSD/2.png" alt></p>
<center><b>图2 SSD详细网络结构图</b></center>
</li>
<li><p>利用了多尺度特征进行检测（300–&gt;38,19,10,5,3,1）。</p>
</li>
</ol>
<h1 id="SSD网络的输出是什么含义？"><a href="#SSD网络的输出是什么含义？" class="headerlink" title="SSD网络的输出是什么含义？"></a>SSD网络的输出是什么含义？</h1><p>SSD包括6个输出，分别是38×38×4×(4+21)，19×19×4×(4+21)，10×10×6×(4+21)，5×5×6×(4+21)，3×3×6×(4+21)，1×1×4×(4+21)，其中(4,4,6,6,6,4)表示该尺度下，每个格子预测的先验框数量，4表示预测的位置信息，21表示20个类别+背景的置信度。</p>
<h1 id="SSD的先验框是如何设置的？"><a href="#SSD的先验框是如何设置的？" class="headerlink" title="SSD的先验框是如何设置的？"></a>SSD的先验框是如何设置的？</h1><ol>
<li>以特征图每个格子的中心坐标为中心，生成一系列的同心先验框。</li>
<li>设置了m=6个尺度的先验框，最底层特征图上的尺度为$S_{min}=0.2$，最高层的为$S_{max}=0.9$，其余层在0.2到0.9之间均等取值。$S_K$表示先验框与输入图像的比例。</li>
<li>每个尺度设置了4或6种（4,6,6,6,4,4）不同的长宽比$a_r\in{1,2,3,1/2,1/3}$，可以计算第k层的先验框的宽为$w_k^a=s_k\sqrt{a_r}$，高为$h_k^a=s_k/\sqrt{a_r}$，此外还有一个边长为$\sqrt{S_kS_{k+1}}$的正方形框，因此每个格子产生6种框。</li>
</ol>
<h1 id="SSD中正负样本如何设定的？"><a href="#SSD中正负样本如何设定的？" class="headerlink" title="SSD中正负样本如何设定的？"></a>SSD中正负样本如何设定的？</h1><ol>
<li>对于每个ground-truth，找到与其IoU最大的先验框设为正样本，这样可以保证每个ground-truth都有一个先验框相匹配。</li>
<li>对于剩余未匹配的先验框，若与某个ground-truth的IoU大于阈值（0.5），则先验框为正样本，其余为负样本。这意味着某个ground-truth可能与多个先验框相匹配（YOLO中，一个ground-truth只有一个对应的先验框）。</li>
<li>训练时，将负样本按背景置信度（预测背景的置信度越小，误差越大）进行排序，选取最低的k个，保证正负样本比例为1:3。</li>
</ol>
<h1 id="SSD的是如何训练的？"><a href="#SSD的是如何训练的？" class="headerlink" title="SSD的是如何训练的？"></a>SSD的是如何训练的？</h1><ol>
<li><p>在ILSVRC上预训练VGG16。</p>
</li>
<li><p>类似于DeepLabv1，将VGG16的前两个全连接层替换为卷积层，并加入了空洞卷积。</p>
</li>
<li><p>采用0.9的Momentum。</p>
</li>
<li><p>采用水平翻转，随机裁剪，颜色扭曲，随机采取区域等数据增强方法。</p>
</li>
<li><p>损失函数由位置误差和分类置信度误差组成：</p>
<p><img src="/2020/07/19/SSD/3.png" alt></p>
<p>位置误差采用Smooth L1损失，预测的$(\Delta x, \Delta y,S_w,S_h)$与RCNN系列中的定义一致。分类置信度误差采用softmax损失（交叉熵损失）。</p>
</li>
</ol>
<h1 id="测试时是SSD如何进行预测的？"><a href="#测试时是SSD如何进行预测的？" class="headerlink" title="测试时是SSD如何进行预测的？"></a>测试时是SSD如何进行预测的？</h1><ol>
<li>对于每个预测框，首先根据类别置信度确定其类别，并过滤掉置信度小于阈值或属于背景的预测框。</li>
<li>按置信度进行排序，保留top-k个预测框。</li>
<li>根据预测框的位置信息对预测框进行修正。</li>
<li>使用NMS过滤掉重叠较大的预测框。</li>
</ol>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/thisiszdy/article/details/89576389" target="_blank" rel="noopener">https://blog.csdn.net/thisiszdy/article/details/89576389</a></p>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
        <tag>目标检测</tag>
      </tags>
  </entry>
</search>
