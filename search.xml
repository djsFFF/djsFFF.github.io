<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World</title>
    <url>/2020/07/13/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<a id="more"></a>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br><span class="line">$ <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型一：R-CNN</title>
    <url>/2020/07/13/RCNN/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于RCNN模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">论文地址：Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation</a><br><img src="/2020/07/13/RCNN/1.png" alt="RCNN网络结构"></p>
<center><b>图1 RCNN网络结构图</b></center>

<a id="more"></a>

<h1 id="简要概述一下RCNN测试时的检测流程？"><a href="#简要概述一下RCNN测试时的检测流程？" class="headerlink" title="简要概述一下RCNN测试时的检测流程？"></a>简要概述一下RCNN测试时的检测流程？</h1><ol>
<li>使用Selective Search在输入图像上提取约2000个候选区域。</li>
<li>缩放每个候选区域到固定尺寸大小，227×227。</li>
<li>将每个候选区域分别输入CNN网络提取特征。</li>
<li>使用二分类SVM分别对每个候选区域进行分类。</li>
<li>对每个类别进行NMS（非极大抑制）。</li>
<li>使用线性回归器分别修正每个候选区域的位置。</li>
</ol>
<h1 id="RCNN是如何对候选区域进行缩放的？"><a href="#RCNN是如何对候选区域进行缩放的？" class="headerlink" title="RCNN是如何对候选区域进行缩放的？"></a>RCNN是如何对候选区域进行缩放的？</h1><p>各向异性缩放且padding=16。</p>
<h1 id="分别介绍一下各向异性和各项同性的缩放？"><a href="#分别介绍一下各向异性和各项同性的缩放？" class="headerlink" title="分别介绍一下各向异性和各项同性的缩放？"></a>分别介绍一下各向异性和各项同性的缩放？</h1><ol>
<li>各向异性直接把图像的宽高拉伸到目标尺寸。</li>
<li>各项同性先按原图像比例进行缩放，然后在再填充到目标价尺寸。</li>
</ol>
<h1 id="RCNN的CNN网络是如何训练的？"><a href="#RCNN的CNN网络是如何训练的？" class="headerlink" title="RCNN的CNN网络是如何训练的？"></a>RCNN的CNN网络是如何训练的？</h1><p><img src="/2020/07/13/RCNN/2.jpg" alt="AlexNet网络结构"></p>
<center><b>图2 AlexNet网络结构图</b></center>

<ol>
<li>使用AlexNet(网络结构如<strong>图2</strong>所示)或其他主干网络（如VGG16），先在ILSVRC2012的图像分类数据集上进行预训练，最后一层输出维度为1000。</li>
<li>将AlexNet最后的1000维Softmax层替换为随机初始化的20+1维Softmax层，其余层使用预训练得到的参数进行初始化，在PASCAL VOC数据集上对预训练后的AlexNet进行fine-tuning（微调）。</li>
<li>Fine-tuning时，定义与ground-truth的IoU大于0.5的候选区域为正样本，否则为负样本（即背景样本），在每次迭代时，采样32个正样本和96个负样本组成一个128的mini-batch。</li>
</ol>
<h1 id="RCNN的SVM分类器是如何训练的？"><a href="#RCNN的SVM分类器是如何训练的？" class="headerlink" title="RCNN的SVM分类器是如何训练的？"></a>RCNN的SVM分类器是如何训练的？</h1><ol>
<li>共训练20个二分类SVM。</li>
<li>使用fine-tuning训练后且去掉最后Softmax层的AlexNet提取候选区域的特征作为SVM的输入。</li>
<li>定义IoU小于0.3的候选区域为负样本，并进行难负样本挖掘，完整包含物体（IoU=1）的候选区域为正样本，其余样本舍弃。</li>
</ol>
<h1 id="RCNN的线性回归器是如何训练的？"><a href="#RCNN的线性回归器是如何训练的？" class="headerlink" title="RCNN的线性回归器是如何训练的？"></a>RCNN的线性回归器是如何训练的？</h1><ol>
<li>共训练20个回归器，正则项系数$\lambda$=10000。</li>
<li>输入为AlexNet的第一个全连接层的4096维输出（这里有点问题，论文里面说的是Pool 5，而我理解的Pool 5的输出时6×6×256的），输出为中心点坐标的平移量和宽高的缩放值。</li>
<li>定义IoU大于0.6的样本作为正样本用于训练。</li>
</ol>
<h1 id="Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）"><a href="#Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）" class="headerlink" title="Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）"></a>Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）</h1><ol>
<li>对AlexNet进行fine-tuning时采用的IoU阈值较小，被分为正样本的候选区域可能只包含部分物体，分类精度较低。</li>
<li>SVM训练时定义完全包含物体的候选区域才是正样本，分类精度较高。因此，使用SVM能够提高分类精度。</li>
</ol>
<h1 id="为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？"><a href="#为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？" class="headerlink" title="为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？"></a>为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？</h1><ol>
<li>Fine-tuning训练时，若IoU阈值设置过高，则可用于的训练样本较少（正样本减少，负样本为正样本的三倍），并且此时AlexNet已进行预训练，易由于样本过少而产生过拟合。因此，设置0.5的IoU阈值只是为了增加可用于训练的样本数量，避免过拟合。  </li>
<li>SVM训练时，为了达到进一步提高分类精度的目的，需要设置更为严格的正负样本分类规则。</li>
</ol>
<h1 id="回归器是如何进行边界框回归的？"><a href="#回归器是如何进行边界框回归的？" class="headerlink" title="回归器是如何进行边界框回归的？"></a>回归器是如何进行边界框回归的？</h1><h2 id="简答"><a href="#简答" class="headerlink" title="简答"></a>简答</h2><p>通过预测候选区域中心点坐标的平移量$\Delta x$，$\Delta y$和宽高的缩放值$S_w$，$S_h$来回归边界框。因此对于每个类别，需要4个回归器分别回归$\Delta x$，$\Delta y$，$S_w$，$S_h$，整个模型就包括20×4个回归器。</p>
<h2 id="详细"><a href="#详细" class="headerlink" title="详细"></a>详细</h2><p>定义$P=(P_x,P_y,P_w,P_h)$表示候选区域的中心坐标和宽高，$G=(G_x,G_y,G_w,G_h)$表示ground-truth的中心坐标和宽高。预测$d_*(P)$（$*$表示$x$，$y$，$w$，$h$，下同）得到平移量$\Delta x=P_wd_x(P)$，$\Delta y=P_hd_y(P)$和缩放值$S_w=exp(d_w(P))$，$S_h=exp(d_h(P))$，目标是使变换后的P与G更接近。<br>定义$\widehat{G}=(\widehat{G}_x,\widehat{G}_y,\widehat{G}_w,\widehat{G}_h)$表示变换后的$P$，其中：<br>$$\widehat{G}_x=P_wd_x(P)+P_x$$<br>$$\widehat{G}_y=P_hd_y(P)+P_y$$<br>$$\widehat{G}_w=P_wexp(d_w(P))$$<br>$$\widehat{G}_h=P_hexp(d_h(P))$$<br>回归器的输入是AlexNet提取的候选区域特征，表示为$\phi(P)$，令$d_*(P)=w^T_*\Phi(P)$，$w_*$就是需要学习的线性变换参数了，可以得到：<br>$$w^T_x\Phi(P)=d_x(P)=(\widehat{G}_x-P_x)/P_w$$<br>$$w^T_y\Phi(P)=d_y(P)=(\widehat{G}_y-P_y)/P_h$$<br>$$w^T_w\Phi(P)=d_w(P)=log(\widehat{G}_w/P_w)$$<br>$$w^T_h\Phi(P)=d_h(P)=log(\widehat{G}_h/P_h)$$<br>定义$t_*$为：<br>$$t_x=(G_x-P_x)/P_w$$<br>$$t_y=(G_y-P_y)/P_h$$<br>$$t_w=log(G_w/P_w)$$<br>$$t_h=log(G_h/P_h)$$<br>目标是使P的映射$\widehat{G}$尽量接近$G$，通过以下优化损失函数求解$w_*$：<br>$$w_*=\underset{\widehat{w}_*}{argmin}\sum(t_*^i-\widehat{w}_*^T\phi(P^i))^2+\lambda&#124;&#124;\widehat{w}_*&#124;&#124;^2$$<br>可通过最小二乘法或梯度下降求解该问题。由此也可以看出，对于每个类别，需要4个回归器分别回归$\Delta x$，$\Delta y$，$S_w$，$S_h$，整个模型就包括20×4个回归器。</p>
<h1 id="回归器为什么不直接预测平移量-Delta-x-和-Delta-y-的值，而是先预测-d-x-P-和-d-y-P-，然后分别乘以-P-w-和-P-h-，间接求出-Delta-x-和-Delta-y-？"><a href="#回归器为什么不直接预测平移量-Delta-x-和-Delta-y-的值，而是先预测-d-x-P-和-d-y-P-，然后分别乘以-P-w-和-P-h-，间接求出-Delta-x-和-Delta-y-？" class="headerlink" title="回归器为什么不直接预测平移量$\Delta x$和$\Delta y$的值，而是先预测$d_x(P)$和$d_y(P)$，然后分别乘以$P_w$和$P_h$，间接求出$\Delta x$和$\Delta y$？"></a>回归器为什么不直接预测平移量$\Delta x$和$\Delta y$的值，而是先预测$d_x(P)$和$d_y(P)$，然后分别乘以$P_w$和$P_h$，间接求出$\Delta x$和$\Delta y$？</h1><p>回归器的输入是候选区域的特征，而每个候选区域在提取特征后的大小时相同的，若是直接预测平移量$\Delta x$和$\Delta y$的值，那么对于任意大小的候选区域，都会得到相同平移量，这显然是有问题的。而分别乘候选区域的宽高$P_w$和$P_h$相当于进行归一化，即尺寸大的候选区域预测的平移量大，尺寸小的候选区域的平移量小。</p>
<h1 id="回归器预测宽高的缩放值为什么要采用exp？"><a href="#回归器预测宽高的缩放值为什么要采用exp？" class="headerlink" title="回归器预测宽高的缩放值为什么要采用exp？"></a>回归器预测宽高的缩放值为什么要采用exp？</h1><p>保证预测值大于0.</p>
<h1 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h1><p>利用CNN提取特征，提升了检测速度。</p>
<h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><p>使用Selective Search提取2000个候选区域，则每张图片需要调用2000次CNN模型，运算量极大导致检测效率低。</p>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
      </tags>
  </entry>
</search>
