<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>模拟面试问答之经典网络模型一：RCNN</title>
    <url>/2020/06/13/RCNN/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于RCNN模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1311.2524" target="_blank" rel="noopener">论文地址：Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation</a><br><img src="/2020/06/13/RCNN/1.png" alt="RCNN网络结构"></p>
<center><b>图1 RCNN网络结构图</b></center>

<a id="more"></a>

<h1 id="简要概述一下RCNN测试时的检测流程？"><a href="#简要概述一下RCNN测试时的检测流程？" class="headerlink" title="简要概述一下RCNN测试时的检测流程？"></a>简要概述一下RCNN测试时的检测流程？</h1><ol>
<li>使用Selective Search在输入图像上提取约2000个候选区域。</li>
<li>缩放每个候选区域到固定尺寸大小，227×227。</li>
<li>将每个候选区域分别输入CNN网络提取特征。</li>
<li>使用二分类SVM分别对每个候选区域进行分类。</li>
<li>对每个类别进行NMS（非极大抑制）。</li>
<li>使用线性回归器分别修正每个候选区域的位置。</li>
</ol>
<h1 id="RCNN是如何对候选区域进行缩放的？"><a href="#RCNN是如何对候选区域进行缩放的？" class="headerlink" title="RCNN是如何对候选区域进行缩放的？"></a>RCNN是如何对候选区域进行缩放的？</h1><p>各向异性缩放且padding=16。</p>
<h1 id="分别介绍一下各向异性和各项同性的缩放？"><a href="#分别介绍一下各向异性和各项同性的缩放？" class="headerlink" title="分别介绍一下各向异性和各项同性的缩放？"></a>分别介绍一下各向异性和各项同性的缩放？</h1><ol>
<li>各向异性直接把图像的宽高拉伸到目标尺寸。</li>
<li>各项同性先按原图像比例进行缩放，然后在再填充到目标价尺寸。</li>
</ol>
<h1 id="RCNN的CNN网络是如何训练的？"><a href="#RCNN的CNN网络是如何训练的？" class="headerlink" title="RCNN的CNN网络是如何训练的？"></a>RCNN的CNN网络是如何训练的？</h1><p><img src="/2020/06/13/RCNN/2.jpg" alt="AlexNet网络结构"></p>
<center><b>图2 AlexNet网络结构图</b></center>

<ol>
<li>使用AlexNet(网络结构如<strong>图2</strong>所示)或其他主干网络（如VGG16），先在ILSVRC2012的图像分类数据集上进行预训练，最后一层输出维度为1000。</li>
<li>将AlexNet最后的1000维Softmax层替换为随机初始化的20+1维Softmax层，其余层使用预训练得到的参数进行初始化，在PASCAL VOC数据集上对预训练后的AlexNet进行fine-tuning（微调）。</li>
<li>Fine-tuning时，定义与ground-truth的IoU大于0.5的候选区域为正样本，否则为负样本（即背景样本），在每次迭代时，采样32个正样本和96个负样本组成一个128的mini-batch。</li>
</ol>
<h1 id="RCNN的SVM分类器是如何训练的？"><a href="#RCNN的SVM分类器是如何训练的？" class="headerlink" title="RCNN的SVM分类器是如何训练的？"></a>RCNN的SVM分类器是如何训练的？</h1><ol>
<li>共训练20个二分类SVM。</li>
<li>使用fine-tuning训练后且去掉最后Softmax层的AlexNet提取候选区域的特征作为SVM的输入。</li>
<li>定义IoU小于0.3的候选区域为负样本，并进行难负样本挖掘，完整包含物体（IoU=1）的候选区域为正样本，其余样本舍弃。</li>
</ol>
<h1 id="RCNN的线性回归器是如何训练的？"><a href="#RCNN的线性回归器是如何训练的？" class="headerlink" title="RCNN的线性回归器是如何训练的？"></a>RCNN的线性回归器是如何训练的？</h1><ol>
<li>共训练20个回归器，正则项系数$\lambda$=10000。</li>
<li>输入为AlexNet的第一个全连接层的4096维输出（这里有点问题，论文里面说的是Pool 5，而我理解的Pool 5的输出时6×6×256的），输出为中心点坐标的平移量和宽高的缩放值。</li>
<li>定义IoU大于0.6的样本作为正样本用于训练。</li>
</ol>
<h1 id="Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）"><a href="#Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）" class="headerlink" title="Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）"></a>Fine-tuning后的AlexNet的输出为21维，已经对各个候选区域进行了分类，为什么还要使用SVM进行分类呢？（或为什么不在AlexNet最后使用Softmax进行分类？）</h1><ol>
<li>对AlexNet进行fine-tuning时采用的IoU阈值较小，被分为正样本的候选区域可能只包含部分物体，分类精度较低。</li>
<li>SVM训练时定义完全包含物体的候选区域才是正样本，分类精度较高。因此，使用SVM能够提高分类精度。</li>
</ol>
<h1 id="为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？"><a href="#为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？" class="headerlink" title="为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？"></a>为什么fine-tuning训练时和SVM训练时的IoU阈值不一样？</h1><ol>
<li>Fine-tuning训练时，若IoU阈值设置过高，则可用于的训练样本较少（正样本减少，负样本为正样本的三倍），并且此时AlexNet已进行预训练，易由于样本过少而产生过拟合。因此，设置0.5的IoU阈值只是为了增加可用于训练的样本数量，避免过拟合。  </li>
<li>SVM训练时，为了达到进一步提高分类精度的目的，需要设置更为严格的正负样本分类规则。</li>
</ol>
<h1 id="回归器是如何进行边界框回归的？"><a href="#回归器是如何进行边界框回归的？" class="headerlink" title="回归器是如何进行边界框回归的？"></a>回归器是如何进行边界框回归的？</h1><h2 id="简答"><a href="#简答" class="headerlink" title="简答"></a>简答</h2><p>通过预测候选区域中心点坐标的平移量$\Delta x$，$\Delta y$和宽高的缩放值$S_w$，$S_h$来回归边界框。因此对于每个类别，需要4个回归器分别回归$\Delta x$，$\Delta y$，$S_w$，$S_h$，整个模型就包括20×4个回归器。</p>
<h2 id="详细"><a href="#详细" class="headerlink" title="详细"></a>详细</h2><p>定义$P=(P_x,P_y,P_w,P_h)$表示候选区域的中心坐标和宽高，$G=(G_x,G_y,G_w,G_h)$表示ground-truth的中心坐标和宽高。预测$d_*(P)$（$*$表示$x$，$y$，$w$，$h$，下同）得到平移量$\Delta x=P_wd_x(P)$，$\Delta y=P_hd_y(P)$和缩放值$S_w=exp(d_w(P))$，$S_h=exp(d_h(P))$，目标是使变换后的P与G更接近。<br>定义$\widehat{G}=(\widehat{G}_x,\widehat{G}_y,\widehat{G}_w,\widehat{G}_h)$表示变换后的$P$，其中：<br>$$\widehat{G}_x=P_wd_x(P)+P_x$$<br>$$\widehat{G}_y=P_hd_y(P)+P_y$$<br>$$\widehat{G}_w=P_wexp(d_w(P))$$<br>$$\widehat{G}_h=P_hexp(d_h(P))$$<br>回归器的输入是AlexNet提取的候选区域特征，表示为$\phi(P)$，令$d_*(P)=w^T_*\Phi(P)$，$w_*$就是需要学习的线性变换参数了，可以得到：<br>$$w^T_x\Phi(P)=d_x(P)=(\widehat{G}_x-P_x)/P_w$$<br>$$w^T_y\Phi(P)=d_y(P)=(\widehat{G}_y-P_y)/P_h$$<br>$$w^T_w\Phi(P)=d_w(P)=log(\widehat{G}_w/P_w)$$<br>$$w^T_h\Phi(P)=d_h(P)=log(\widehat{G}_h/P_h)$$<br>定义$t_*$为：<br>$$t_x=(G_x-P_x)/P_w$$<br>$$t_y=(G_y-P_y)/P_h$$<br>$$t_w=log(G_w/P_w)$$<br>$$t_h=log(G_h/P_h)$$<br>目标是使P的映射$\widehat{G}$尽量接近$G$，通过以下优化损失函数求解$w_*$：<br>$$w_*=\underset{\widehat{w}_*}{argmin}\sum(t_*^i-\widehat{w}_*^T\phi(P^i))^2+\lambda&#124;&#124;\widehat{w}_*&#124;&#124;^2$$<br>可通过最小二乘法或梯度下降求解该问题。由此也可以看出，对于每个类别，需要4个回归器分别回归$\Delta x$，$\Delta y$，$S_w$，$S_h$，整个模型就包括20×4个回归器。</p>
<h1 id="回归器为什么不直接预测平移量-Delta-x-和-Delta-y-的值，而是先预测-d-x-P-和-d-y-P-，然后分别乘以-P-w-和-P-h-，间接求出-Delta-x-和-Delta-y-？"><a href="#回归器为什么不直接预测平移量-Delta-x-和-Delta-y-的值，而是先预测-d-x-P-和-d-y-P-，然后分别乘以-P-w-和-P-h-，间接求出-Delta-x-和-Delta-y-？" class="headerlink" title="回归器为什么不直接预测平移量$\Delta x$和$\Delta y$的值，而是先预测$d_x(P)$和$d_y(P)$，然后分别乘以$P_w$和$P_h$，间接求出$\Delta x$和$\Delta y$？"></a>回归器为什么不直接预测平移量$\Delta x$和$\Delta y$的值，而是先预测$d_x(P)$和$d_y(P)$，然后分别乘以$P_w$和$P_h$，间接求出$\Delta x$和$\Delta y$？</h1><p>回归器的输入是候选区域的特征，而每个候选区域在提取特征后的大小时相同的，若是直接预测平移量$\Delta x$和$\Delta y$的值，那么对于任意大小的候选区域，都会得到相同平移量，这显然是有问题的。而分别乘候选区域的宽高$P_w$和$P_h$相当于进行归一化，即尺寸大的候选区域预测的平移量大，尺寸小的候选区域的平移量小。</p>
<h1 id="回归器预测宽高的缩放值为什么要采用exp？"><a href="#回归器预测宽高的缩放值为什么要采用exp？" class="headerlink" title="回归器预测宽高的缩放值为什么要采用exp？"></a>回归器预测宽高的缩放值为什么要采用exp？</h1><p>保证预测值大于0.</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>优点：RCNN引入CNN提取特征，取代手工设计特征，并提升了检测速度；采用了迁移学习的思想，先在大数据集上对模型进行预训练，然后在目标数据集上面进行fine-tuning。</li>
<li>缺点：RCNN使用Selection Search提取2000个候选区域，不够精确；需要对每个候选区域单独提取特征，无法共享特征，且内存占用和耗时较大；训练过程分为三个阶段，繁琐且耗时较大。</li>
</ol>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
      </tags>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型二：Fast RCNN</title>
    <url>/2020/07/01/FastRCNN/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于Fast RCNN模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1504.08083" target="_blank" rel="noopener">论文地址：Fast R-CNN</a><br><img src="/2020/07/01/FastRCNN/1.jpg" alt="Fast RCNN网络结构"></p>
<center><b>图1 Fast RCNN网络结构图</b></center>

<a id="more"></a>

<h1 id="简要概述一下Fast-RCNN测试时的检测流程？"><a href="#简要概述一下Fast-RCNN测试时的检测流程？" class="headerlink" title="简要概述一下Fast RCNN测试时的检测流程？"></a>简要概述一下Fast RCNN测试时的检测流程？</h1><ol>
<li>使用Selective Search在输入图像上提取约2000个候选区域。</li>
<li>将原始图像输入卷积网络，获得最后一个池化层之前的特征图（16倍下采样）。</li>
<li>对于每个候选区域，RoI pooling层将候选区域定位到特征图中的对应区域产生RoI，然后将每个RoI转化为相同尺寸（7×7）。</li>
<li>通过全连接层将RoI转化为一维向量，分别输入并行的分类器和回归器。分类器由一个全连接层和Softmax组成，对每一个RoI输出20+1个类别概率。回归器输出通过一个全连接层对每一个RoI输出20×4维向量，即所有类别下回归RoI的位置和大小。</li>
</ol>
<h1 id="描述一下RoI-pooling的工作原理？"><a href="#描述一下RoI-pooling的工作原理？" class="headerlink" title="描述一下RoI pooling的工作原理？"></a>描述一下RoI pooling的工作原理？</h1><p>先将候选区域定位到特征图中的对应区域产生RoI，然后将RoI划分为H×W的区域，然后分别取每个区域的最大值代替该区域，从而将RoI尺寸调整为H×W。</p>
<h1 id="两次坐标量化是指什么？"><a href="#两次坐标量化是指什么？" class="headerlink" title="两次坐标量化是指什么？"></a>两次坐标量化是指什么？</h1><ol>
<li>第一次量化时将候选区域映射到特征图上时，需要将候选区域坐标除以16并取整。</li>
<li>第二次量化是指RoI pooling时，需要将RoI划分为H×W个部分，对左上角坐标采用向下取整，对右下角坐标采用向上取整。两次量化操作会引入误差，Mask RCNN中会解决这一问题。</li>
</ol>
<h1 id="Fast-RCNN是如何训练的？"><a href="#Fast-RCNN是如何训练的？" class="headerlink" title="Fast RCNN是如何训练的？"></a>Fast RCNN是如何训练的？</h1><ol>
<li>以VGG16为例，先在ImageNet上训练一个1000类的分类网络。</li>
<li>修改预训练后的网络结构，将最后一个池化层替换为RoI pooling层；将最后一个全连接层替换为并行的分类器和回归器；网络输入替换为图像+候选区域集合。</li>
<li>将修改后的网络在Pascal VOC上进行fine-tuning，定义IoU大于0.5的为正样本，IoU为0.1-0.5之间的为负样本，每次迭代时包括2张图像，每张图像随机采样16个正样本和48个负样本用于训练；采样0.5概率的水平翻转进行数据增强。</li>
<li>采用分类损失和回归损失的联合组成的多任务损失函数进行训练。</li>
</ol>
<h1 id="Fast-RCNN的损失函数是如何构成的？"><a href="#Fast-RCNN的损失函数是如何构成的？" class="headerlink" title="Fast RCNN的损失函数是如何构成的？"></a>Fast RCNN的损失函数是如何构成的？</h1><h2 id="简答"><a href="#简答" class="headerlink" title="简答"></a>简答</h2><p>Fast RCNN采用多任务损失函数，由分类损失和回归损失联合组成。分类采用交叉熵损失函数，回归采用Smooth L1损失函数。</p>
<h2 id="详细"><a href="#详细" class="headerlink" title="详细"></a>详细</h2><p>Fast RCNN的多任务损失函数如下：<br>$$L(p,u,t^u,v)=L_{cls}(p,u)+\lambda [u\geq 1]L_{loc}(t^u,v)$$<br>其中，$L_{cls}(p,u)=-logp_u$表示真实分类u的概率$p_u$的对数损失。$\lambda$用于平衡分类损失和回归损失，通常取1。$[u\geq 1]$为指示函数，$u\geq 1$时取1否则取0，即当p为负样本时忽略回归损失。$L_{loc}(t^u,v)$为四个Smooth L1损失的和，分别是两个平移量和两个缩放值（具体参考上一篇关于RCNN的博客）。Smooth L1损失函数如下所示：<br>$$Smooth_{L1}(x)=\begin{cases} 0.5x^2 &amp; if&#124;x&#124;&lt;1 \\ &#124;x&#124;-0.5 &amp; otherwise \end{cases}$$<br>Smooth L1损失函数在x较大时（训练初期）采取L1损失函数形式，避免了L2损失在训练初期导数大的问题；在x较小（训练后期）时采取L2损失函数形式，避免了L1损失函数在训练后期导数大的问题。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>优点：Fast RCNN解决了RCNN的两大问题：①一次性提取特征然后对候选区域进行特征映射，实现特征共享，极大地节约了时间和空间消耗；②将RCNN的三个模型整合为一个模型，一次性进行分类和回归。</li>
<li>缺点：仍然存在与RCNN一样的问题，即使用Selective Search进行候选框提取。</li>
</ol>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
      </tags>
  </entry>
  <entry>
    <title>模拟面试问答之经典网络模型三：FasterRCNN</title>
    <url>/2020/07/15/FasterRCNN/</url>
    <content><![CDATA[<p>本文总结了面试过程中可能问到的关于Faster RCNN模型的一些问题。</p>
<p><a href="https://arxiv.org/abs/1506.01497" target="_blank" rel="noopener">论文地址：Faster R-CNN</a><br><img src="/2020/07/15/FasterRCNN/1.png" alt="Faster RCNN网络结构"></p>
<center><b>图1 Faster RCNN网络结构图</b></center>

<a id="more"></a>

<h1 id="简要概述一下Fast-RCNN测试时的检测流程？"><a href="#简要概述一下Fast-RCNN测试时的检测流程？" class="headerlink" title="简要概述一下Fast RCNN测试时的检测流程？"></a>简要概述一下Fast RCNN测试时的检测流程？</h1><ol>
<li>调整输入图像尺寸为16的倍数。</li>
<li>使用CNN（以VGG16为例）提取特征图。</li>
<li>RPN（Region Proposal Network）在特征图上生成一系列anchor box，并通过两个分支分别判断anchor box是否包含物体以及粗略位置修正。</li>
<li>将特征图和anchor boxes一起输入到RoI pooling层，与Fast RCNN一样，对于每个anchor boxes，RoI pooling层将候选区域定位到特征图中的对应区域产生RoI，然后将每个RoI转化为相同尺寸（7×7）。</li>
<li>通过全连接层将RoI转化为一维向量，分别输入并行的分类器和回归器。分类器由一个全连接层和Softmax组成，对每一个RoI输出20+1个类别概率。回归器输出通过一个全连接层对每一个RoI输出20×4维向量，即所有类别下回归RoI的位置和大小。</li>
<li>经过两个全连接+ReLU层将RoI转化为一维向量，分别输入并行的分类器和回归器。分类器由一个全连接层和Softmax组成，对每一个RoI输出80+1个类别概率。回归器输出通过一个全连接层对每一个RoI输出80×4维向量，即所有类别下回归RoI的位置和大小。</li>
</ol>
<h1 id="Faster-RCNN相对于Fast-RCNN的主要改进在什么地方？"><a href="#Faster-RCNN相对于Fast-RCNN的主要改进在什么地方？" class="headerlink" title="Faster RCNN相对于Fast RCNN的主要改进在什么地方？"></a>Faster RCNN相对于Fast RCNN的主要改进在什么地方？</h1><ol>
<li>Faster RCNN不再使用Selective Search提取候选区域，而是采用卷积网络（RPN）产生候选框。</li>
<li>RPN网络在生成候选框后会对候选框进行筛选，只保留可能包含物体的候选框（～300个），为后续计算节约计算成本。</li>
</ol>
<h1 id="介绍一下RPN网络？"><a href="#介绍一下RPN网络？" class="headerlink" title="介绍一下RPN网络？"></a>介绍一下RPN网络？</h1><p><img src="/2020/07/15/FasterRCNN/3.png" alt="Faster RCNN网络结构"></p>
<center><b>图2 RPN网络结构图</b></center>

<ol>
<li>首先通过一个3×3的卷积进一步集中特征信息，然后在特征图上的每个特征点生成9个anchor box（三个尺度，三个比例），把生成的anchor boxes分别送入分类分支和回归分支。</li>
<li>对于分类分支，通过一个1×1卷积+Softmax输出每个anchor box存在物体的概率。</li>
<li>对于回归分支，通过一个1×1卷积输出每个anchor box的粗略位置估计，包括2个平移量（$\Delta x$，$\Delta y$）和两个缩放量($S_h$，$S_w$)，具体参考前面关RCNN的博客。</li>
<li>最后Proposal层根据分类和回归分支结果筛选候选框。首先根据回归结果修正候选框位置，然后根据分类结果筛选出前k（6000）个存在物体概率最高的候选框，并去除尺寸较小的和超出边界的候选框，再使用NMS剔除重叠候选框（0.7阈值），最后将筛选结果（约300个）送入RoI pooling层。</li>
</ol>
<h1 id="Faster-RCNN是如何训练的？"><a href="#Faster-RCNN是如何训练的？" class="headerlink" title="Faster RCNN是如何训练的？"></a>Faster RCNN是如何训练的？</h1><ol>
<li>交替训练（论文采用）：Faster RCNN可以看做时Fast RCNN + RPN，可以将Fast RCNN和RPN单独进行训练，但这两部分共享VGG16部分。<br>① 首先在ImageNet上面预训练VGG16；<br>② 使用①中的VGG16参数结合RPN进行训练；<br>③ 使用①中的VGG16参数组成Fast RCNN，并利用训练后的RPN网络生成候选框来训练Fast RCNN；<br>④ 使用③中的VGG16参数并结合RPN进行训练，VGG16参数不更新。<br>⑤ 使用③中的VGG16参数Fast RCNN，并利用④中的RPN网络生成候选框来训练Fast RCNN，VGG16参数不更新。</li>
<li>近似联合训练：将Faster RCNN整体进行训练，包括四个损失函数，RPN二分类损失，RPN回归损失，最后的多分类损失和回归损失。</li>
</ol>
<h1 id="Faster-RCNN的损失函数是如何构成的？"><a href="#Faster-RCNN的损失函数是如何构成的？" class="headerlink" title="Faster RCNN的损失函数是如何构成的？"></a>Faster RCNN的损失函数是如何构成的？</h1><ol>
<li>对于RPN训练，定义IoU最大或者IoU大于0.7的候选框为正样本，IoU小于0.3的候选框为负样本，其余候选框舍弃，每张图片随机采样128个正样本和128个负样本用于训练，若正样本过少，则增加负样本，保持样本总数为256。RPN的多任务损失函数为：<br>$$L({p_i},{t_i})=\frac {1}{N_{cls}}\sum_i L_{cls}(p_i,p_i^*)+\lambda \frac {1}{N_{reg}}\sum_i p_i^*L_{reg}(t_i,t_i^*)$$<br>其中，对于正样本$p_i^*=1$，否则为0。$L({p_i},{t_i})=-logp_i$表示第i个候选框含有物体的概率$p_i$的对数损失。$L_{loc}(t^u,v)$为四个Smooth L1损失的和，分别是两个平移量和两个缩放值（关于Smooth L1损失可参考上一篇关于Fast RCNN的博客）。</li>
<li>对于网络末端的分类器和回归器的训练，采用与Fast RCNN相同的损失函数。</li>
<li>实际上RPN的损失函数与Fast RCNN唯一的区别就在于一个是二分类，一个是多分类。此外，两者对于正负样本的划分有所区别。</li>
</ol>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol>
<li>优点：Faster RCNN利用RPN生成候选框，舍弃了耗时的Selective Search方法，无论是检测速度和精度都得到了提升。</li>
<li>缺点：Faster RCNN的两阶段方法无法达到实时检测的效果。</li>
</ol>
]]></content>
      <categories>
        <category>面试</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>经典网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux-File</title>
    <url>/2020/07/15/Linux-File/</url>
    <content><![CDATA[<p>本文总结了Linux系统中对文件属性和权限进行操作的常用命令。</p>
<a id="more"></a>

<h1 id="ls-l用于查看文件属性"><a href="#ls-l用于查看文件属性" class="headerlink" title="ls -l用于查看文件属性"></a><code>ls -l</code>用于查看文件属性</h1><pre><code>➜  ~ ls -l 
total 21776
drwxr-xr-x 26 dong dong     4096 11月 29  2019  anaconda3
drwxr-xr-x  8 dong dong     4096 7月  13 23:46  Clover</code></pre><p>每一个文件开头10个字符含义如下图：<br><img src="/2020/07/15/Linux-File/1.png" alt><br>第0位文件类型包括：<code>d</code>目录、<code>-</code>文件及其他（<code>l</code>、<code>b</code>、<code>c</code>），第1-3位表示该文件所有者的权限，第4-6位表示所有者同组用户的权限，第7-9位表示其他用户的权限。<code>r</code>读、<code>w</code>写、<code>x</code>执行（execute）表示拥有对应权限，<code>-</code>表示没有该权限。</p>
<h1 id="chown-R-属主名-文件或目录用于更改文件属主"><a href="#chown-R-属主名-文件或目录用于更改文件属主" class="headerlink" title="chown [-R] 属主名 文件或目录用于更改文件属主"></a><code>chown [-R] 属主名 文件或目录</code>用于更改文件属主</h1><p>加上参数<code>-R</code>表示递归更改文件属主。</p>
<h1 id="chgrp-R-属组名-文件或目录用于更改文件属组"><a href="#chgrp-R-属组名-文件或目录用于更改文件属组" class="headerlink" title="chgrp [-R] 属组名 文件或目录用于更改文件属组"></a><code>chgrp [-R] 属组名 文件或目录</code>用于更改文件属组</h1><p>加上参数<code>-R</code>表示递归更改文件属组。</p>
<h1 id="chmod-R-xyz-文件或目录用于更改文件的9个权限"><a href="#chmod-R-xyz-文件或目录用于更改文件的9个权限" class="headerlink" title="chmod [-R] xyz 文件或目录用于更改文件的9个权限"></a><code>chmod [-R] xyz 文件或目录</code>用于更改文件的9个权限</h1><p>加上参数<code>-R</code>表示递归更改文件权限。<br><code>xyz</code>表示要设置的权限数字，每个权限数字为3个权限分数之和，各权限分数对照如下：</p>
<ul>
<li><code>r</code>：4</li>
<li><code>w</code>：2</li>
<li><code>x</code>：1</li>
</ul>
<p>例如<code>7=rwx</code>，<code>0=---</code>，<code>drwxr-xr-x</code>的权限数字为<code>755</code>。</p>
<p>或者可以使用<code>chmod u=rwx,g=rx,o=r 文件名</code>的命令来设定文件的权限，具体如下表所示：</p>
<table>
<thead>
<tr>
<th>chmod</th>
<th>u</th>
<th>+（加入）</th>
<th>r</th>
<th>文件或目录</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>g</td>
<td>-（除去）</td>
<td>w</td>
<td></td>
</tr>
<tr>
<td></td>
<td>o</td>
<td>=（设定</td>
<td>x</td>
<td></td>
</tr>
<tr>
<td></td>
<td>a</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
]]></content>
      <categories>
        <category>Linux基础</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
</search>
